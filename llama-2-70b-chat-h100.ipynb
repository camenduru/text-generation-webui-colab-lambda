{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone -b v1.8-lambda https://github.com/camenduru/text-generation-webui /home/ubuntu/text-generation-webui\n",
    "%cd /home/ubuntu/text-generation-webui\n",
    "!pip install -r requirements.txt\n",
    "!pip install -U torch torchvision torchaudio torchtext torchdata --extra-index-url https://download.pytorch.org/whl/cu118\n",
    "!pip install protobuf==3.20.3 -U\n",
    "\n",
    "%cd /home/ubuntu\n",
    "!git clone https://github.com/TimDettmers/bitsandbytes\n",
    "%cd /home/ubuntu/bitsandbytes\n",
    "!sudo CUDA_VERSION=118 make cuda11x\n",
    "!sudo python setup.py install\n",
    "!cp /home/ubuntu/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cuda118.so /home/ubuntu/.local/lib/python3.8/site-packages/bitsandbytes/libbitsandbytes_cpu.so\n",
    "\n",
    "!sudo apt -y install -qq aria2\n",
    "\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00001-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00001-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00002-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00002-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00003-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00003-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00004-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00004-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00005-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00005-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00006-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00006-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00007-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00007-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00008-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00008-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00009-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00009-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00010-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00010-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00011-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00011-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00012-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00012-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00013-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00013-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00014-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00014-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/model-00015-of-00015.safetensors -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model-00015-of-00015.safetensors\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/raw/main/model.safetensors.index.json -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o model.safetensors.index.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/raw/main/special_tokens_map.json -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o special_tokens_map.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/resolve/main/tokenizer.model -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o tokenizer.model\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/raw/main/tokenizer_config.json -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o tokenizer_config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/raw/main/config.json -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o config.json\n",
    "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M https://huggingface.co/4bit/Llama-2-70b-chat-hf/raw/main/generation_config.json -d /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf -o generation_config.json\n",
    "\n",
    "%cd /home/ubuntu/text-generation-webui\n",
    "!python server.py --share --chat --multi-user --listen-port 8266 --load-in-8bit --model /home/ubuntu/text-generation-webui/models/Llama-2-70b-chat-hf"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
